_BASE_: /h/rgoyal/code/minotaur/config/all_tasks/BASE.yaml

# Hyperparams
lr: 1e-4                                            # modded for 16 GPUs
lr_backbone: 2e-5                                   # modded for 16 GPUs
# text_encoder_lr: 1e-4

flop_count_mode: False

# Model
model:
  name: 
    tubedetr: tubedetr_unified_single_DL
    transformer: transformer_unified
    backbone: backbone

  segment_types: ["fg", "left_trun", "right_trun", "bg"]
  use_score_per_frame: True                           # to predict score per frame

  use_single_query_embed: False

  # mq:
  #   video_max_len: 400
  #   use_segment_type_classification: False  # classify segments into fg, left_trun, right_trun, bg
  #   use_frame_action_classification: False  # classify frames into one of N possible actions (used for regularization)
  #   use_class_text_embeddings: False        # use class textual embeddings for queries instead of one-hot encodings
  #   use_text_encoder: False                 #  
  #   concat_slowfast_features: false         # concat slowfast featurs with 2D CNN features

  # nlq:
  #   video_max_len: 400
  #   use_sentence_text_embeddings: False

  vq2d:
    video_max_len: 200
    scale_loss_by_factor: 1.0
    use_projection_layer: True
    freeze_backbone_during_query_projection: False
    use_text_query: False

joint:
  scale_loss:
    nlq: 1.0
    mq: 1.0
    vq2d: 1.0



# tasks
tasks:
  names: []
train_strategy: "concat"                            # ['round_robin']




# Train arguments
train_flags:
  print_freq: 100
  
  # mq:
  #   stride: 5
  #   prob_segment_type: [0.25, 0.25, 0.25, 0.25]
  #   eval_set_size:
  #     train: 100
  #     debug: 10
  #   use_fps_jitter: False                   # use fps jitter during training
  #   pretrain_backbone: False                # flag for pretraining mq backbone with aciton classification

  # nlq:
  #   stride: 5
  #   prob_segment_type: [0.75, 0.0, 0.0, 0.25]
  #   eval_set_size:
  #     train: 200
  #     debug: 10
  #   remove_empty_queries: True

  vq2d:
    stride: 0
    eval_set_size:
      train: 200
      debug: 10
    p_text_query: 0.0



# Eval arguments
eval_flags:
  print_freq: 100
  use_full_video_for_eval: True                     # flag for using full videos or not
  plot_pred: False                                  # to plot predictions

  # mq:
  #   stride: 0
  #   generate_and_save_preds_for_all_captions: False
  #   scale_prediction: [1, 3, 5, 10, 25]
  #   window_step_size: 100
  #   win_size_around_peak: [200, 400, 600]

  # nlq:
  #   stride: 5
  #   scale_prediction: [1]
  #   window_step_size: 100
  #   win_size_around_peak: [100]

  #   sample_val_set:
  #     enable: false
  #     path_dict: /h/rgoyal/code/efficient-memory-net/TubeDETR_3c32cc9/notebooks/assets/dict_key_to_qtype_sampled_10.pkl
  #   write_video_frames_only: false

  vq2d:
    stride: 0
    window_step_size: 50
    win_size_around_peak: 35
    p_text_query: 0.0



# Loss coefficients
loss_coef:
  score_per_frame_loss_coef: 2
  # mq:
  #   segment_type_loss_coef: 5
  #   frame_action_classification_loss_coef: 2


flops_exp:
  enable: False
  downsample_factor: 1



misc:
  # MISC - MQ
  # mq:
  #   extract_backbone_features: False        # flag for extracting mq backbone features
  #   path_extract_backbone_features: /private/home/raghavgoyal/data/mq_root/extracted_backbone_features/dummy